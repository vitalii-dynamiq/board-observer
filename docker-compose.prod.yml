# Board Observer - Production Docker Compose
# Usage: docker compose -f docker-compose.prod.yml up -d
#
# Requires .env.prod file with production values
#
# Ports used by Board Observer (to avoid conflicts):
#   - Frontend:  4280
#   - Backend:   4281
#   - Database:  5481 (not exposed in production)

services:
  # PostgreSQL Database
  db:
    image: postgres:15-alpine
    container_name: board-observer-db
    restart: always
    environment:
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:?DB_PASSWORD is required}
      POSTGRES_DB: ${DB_NAME:-board_observer}
    volumes:
      - board_observer_prod_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - board-observer-internal
    # Database port NOT exposed in production
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M

  # Redis for rate limiting and caching
  redis:
    image: redis:7-alpine
    container_name: board-observer-redis
    restart: always
    command: redis-server --requirepass ${REDIS_PASSWORD:?REDIS_PASSWORD is required}
    volumes:
      - board_observer_redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--pass", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - board-observer-internal
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  # Backend API (Node.js/Express)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: board-observer-api
    restart: always
    environment:
      DATABASE_URL: postgresql://${DB_USER:-postgres}:${DB_PASSWORD}@db:5432/${DB_NAME:-board_observer}?schema=public
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      PORT: 4281
      NODE_ENV: production
      FRONTEND_URL: ${FRONTEND_URL:?FRONTEND_URL is required}
      
      # AI Services
      RECALL_API_KEY: ${RECALL_API_KEY:?RECALL_API_KEY is required}
      RECALL_API_URL: ${RECALL_API_URL:-https://us-west-2.recall.ai/api/v1}
      RECALL_WEBHOOK_SECRET: ${RECALL_WEBHOOK_SECRET:?RECALL_WEBHOOK_SECRET is required}
      WEBHOOK_BASE_URL: ${WEBHOOK_BASE_URL:?WEBHOOK_BASE_URL is required}
      
      OPENAI_API_KEY: ${OPENAI_API_KEY:?OPENAI_API_KEY is required}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4o-mini}
      
      ELEVENLABS_API_KEY: ${ELEVENLABS_API_KEY}
      ELEVENLABS_VOICE_ID: ${ELEVENLABS_VOICE_ID}
      TTS_PROVIDER: ${TTS_PROVIDER:-openai}
      
      TRANSCRIPTION_PROVIDER: ${TRANSCRIPTION_PROVIDER:-assembly_ai_v3_streaming}
      
      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-info}
    ports:
      - "4281:4281"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4281/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - board-observer-internal
      - board-observer-external
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Frontend (Next.js)
  frontend:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:?NEXT_PUBLIC_API_URL is required}
    container_name: board-observer-frontend
    restart: always
    environment:
      NODE_ENV: production
      PORT: 4280
    ports:
      - "4280:4280"
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4280"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - board-observer-external
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  board_observer_prod_data:
    driver: local
  board_observer_redis_data:
    driver: local

networks:
  # Internal network for database/redis (not exposed)
  board-observer-internal:
    driver: bridge
    internal: true
  # External network for frontend/backend (exposed)
  board-observer-external:
    driver: bridge
